{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9592\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "if not 'sc' in globals():\n",
    "    sc = pyspark.SparkContext()\n",
    "    \n",
    "def is_it_prime(number):\n",
    "    # make sure n is a positive integer\n",
    "    number = abs(int(number))\n",
    "    \n",
    "    # simple tests\n",
    "    if number < 2:\n",
    "        return False\n",
    "    \n",
    "    # 2 is prime\n",
    "    if number == 2:\n",
    "        return True\n",
    "    # other even numbers aren't\n",
    "    if not number & 1:\n",
    "        return False\n",
    "    \n",
    "    # check whether number is divisible into it's square root\n",
    "    for x in range(3, int(number**0.5)+1, 2):\n",
    "        if number % x == 0:\n",
    "            return False\n",
    "        \n",
    "    #if we get this far we are good\n",
    "    return True\n",
    "\n",
    "# create a set of numbers to 100,000\n",
    "numbers = sc.parallelize(range(100000))\n",
    "\n",
    "# count out the number of primes we found\n",
    "print (numbers.filter(is_it_prime).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220 sentences\n",
      "3463 bigrams\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(36, ('of', 'the')),\n",
       " (15, ('the', 'mall')),\n",
       " (12, ('on', 'the')),\n",
       " (12, ('to', 'the')),\n",
       " (12, ('At', 'this')),\n",
       " (11, ('the', 'guards')),\n",
       " (11, ('at', 'the')),\n",
       " (11, ('in', 'the')),\n",
       " (9, ('and', 'the')),\n",
       " (9, ('out', 'of'))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "if not 'sc' in globals():\n",
    "    sc = pyspark.SparkContext()\n",
    "     \n",
    "sentences = sc.textFile('2600raid.txt') \\\n",
    "    .glom() \\\n",
    "    .map(lambda x: \" \".join(x)) \\\n",
    "    .flatMap(lambda x: x.split(\".\"))\n",
    "print(sentences.count(),\"sentences\")\n",
    "\n",
    "bigrams = sentences.map(lambda x:x.split()) \\\n",
    "    .flatMap(lambda x: [((x[i],x[i+1]),1) for i in range(0,len(x)-1)])\n",
    "print(bigrams.count(),\"bigrams\")\n",
    "\n",
    "frequent_bigrams = bigrams.reduceByKey(lambda x,y:x+y) \\\n",
    "    .map(lambda x:(x[1],x[0])) \\\n",
    "    .sortByKey(False)\n",
    "frequent_bigrams.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
